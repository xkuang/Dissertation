{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "import fileinput\n",
    "import plotly.graph_objs as go\n",
    "import sklearn\n",
    "import struct\n",
    "import re\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import whiten\n",
    "from sklearn import cluster\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import urllib3\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import plotly.plotly as py\n",
    "import http\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.datasets import make_circles\n",
    "import plotly.graph_objs as go\n",
    "from numpy import genfromtxt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///C:/Users/pinouche/Documents/ImperialData/FOLD_3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the Google cloud for FOLD_3. (ON THE GOOGLE CLOUD STORAGE)\n",
    "\n",
    "# Import the name of files from virtual machine\n",
    "\n",
    "my_data = genfromtxt('FOLD3.txt', delimiter='\\n', dtype=str)\n",
    "\n",
    "url =  \"https://storage.googleapis.com/bucket-pinouche/ImperialData/FOLD_3\"\n",
    "\n",
    "dic = {}\n",
    "number_of_files = 0\n",
    "\n",
    "for filename in my_data:\n",
    "    print(filename)\n",
    "    f = urllib.request.urlopen(url+'/'+filename)\n",
    "    with open(os.path.basename(url), \"wb\") as local_file:\n",
    "        local_file.write(f.read())\n",
    "        dic[filename] = sio.loadmat(local_file.name)\n",
    "    \n",
    "    number_of_files = number_of_files + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Annotation folder is stored on the virtual machine instance directly (ON THE VIRTUAL MACHINE)\n",
    "\n",
    "even_names_files = list()\n",
    "index = 0\n",
    "\n",
    "for name in name_of_files:\n",
    "    if(index%2 == 0):\n",
    "        even_names_files.append(name[:-10])\n",
    "    index += 1\n",
    "\n",
    "dic2 = {}\n",
    "number_of_files = 0\n",
    "path = r'/home/uriot_thomas/two'\n",
    "\n",
    "for filename in even_names_files:\n",
    "    dic2[filename] = sio.loadmat(path+'/'+filename+'/'+'meanAnnotation.mat')\n",
    "    number_of_files = number_of_files + 1\n",
    "    \n",
    "sequences_shape = list()\n",
    "mean_annotations = list()\n",
    "\n",
    "for filename in even_names_files:\n",
    "    mean_annotations.append(dic2[filename]['annotations'])\n",
    "    sequences_shape.append(dic2[filename]['annotations'].shape[0])\n",
    "\n",
    "array_annotations_FOLD_3 = np.concatenate(np.asarray(mean_annotations), axis=0)\n",
    "\n",
    "print([number_of_files, array_annotations_FOLD_3.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, ['20120213_seq1_01_01.mat', '20120213_seq1_01_02.mat', '20120213_seq2_01_01.mat', '20120213_seq2_01_02.mat', '20120326_seq3_01_01.mat', '20120326_seq3_01_02.mat', '20120423_seq10_01_01.mat', '20120423_seq10_01_02.mat', '20120423_seq11_01_01.mat', '20120423_seq11_01_02.mat', '20120423_seq1_01_01.mat', '20120423_seq1_01_02.mat', '20120423_seq2_01_01.mat', '20120423_seq2_01_02.mat', '20120423_seq3_01_01.mat', '20120423_seq3_01_02.mat', '20120423_seq4_01_01.mat', '20120423_seq4_01_02.mat', '20120423_seq6_01_01.mat', '20120423_seq6_01_02.mat', '20120423_seq8_01_01.mat', '20120423_seq8_01_02.mat', '20120423_seq9_01_01.mat', '20120423_seq9_01_02.mat', '20120430_seq10_01_01.mat', '20120430_seq10_01_02.mat', '20120430_seq11_01_01.mat', '20120430_seq11_01_02.mat', '20120430_seq12_01_01.mat', '20120430_seq12_01_02.mat', '20120430_seq2_01_01.mat', '20120430_seq2_01_02.mat', '20120430_seq3_01_01.mat', '20120430_seq3_01_02.mat', '20120430_seq5_01_01.mat', '20120430_seq5_01_02.mat', '20120430_seq7_01_01.mat', '20120430_seq7_01_02.mat', '20120430_seq9_01_01.mat', '20120430_seq9_01_02.mat']]\n"
     ]
    }
   ],
   "source": [
    "# Getting the features data into usable matrix format\n",
    "\n",
    "def dataMatrix(array1, array2):\n",
    "\n",
    "    person1 = list()\n",
    "    person2 = list()\n",
    "\n",
    "    for frame in range(0, array1.shape[2]):\n",
    "        for sift in range(0,49):\n",
    "            person1.append(array1[sift,:,frame])\n",
    "            person2.append(array2[sift,:,frame])\n",
    "\n",
    "    tmp_arr_mat1 = np.reshape(np.asarray(person1),(array1.shape[2],6272))\n",
    "    tmp_arr_mat2 = np.reshape(np.asarray(person2),(array2.shape[2],6272))\n",
    "    frame_vector = np.concatenate([tmp_arr_mat1,tmp_arr_mat2], axis=1)\n",
    "    \n",
    "    return(frame_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# Get all the values from the SIFT values for each of the frame from the dictionnary\n",
    "\n",
    "key=0\n",
    "concat = []\n",
    "\n",
    "for val in name_of_files:\n",
    "    if(key%2 == 0):\n",
    "        person1 = dic[val]['SIFT']\n",
    "    else:\n",
    "        person2 = dic[val]['SIFT']\n",
    "        concat.append(dataMatrix(person1, person2))\n",
    "    key +=1\n",
    "        \n",
    "Big_list = np.concatenate(concat)\n",
    "print(Big_list.shape)\n",
    "\n",
    "# The dimensions of the Big_list (data matrix) is 20640 by 12544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead of concatenating together the vectors for the 2 people, use the average for the data matrix. Note that later on,\n",
    "# the response we have for each frame is the same for the 2 people (i.e there is a conflict intensity for the overall \n",
    "# interaction and not a seperated conflict value for each of the interlocutors). So this approach may be a better way.\n",
    "\n",
    "Person1_columns = Big_list[:,:(49*128)]\n",
    "Person2_columns = Big_list[:,(49*128):]\n",
    "print([Person1_columns.shape,Person2_columns.shape])\n",
    "Average_Big_list_FOLD_3 = (Person1_columns + Person2_columns)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Peform PCA on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots the annotation for a whole video sequence as an example\n",
    "\n",
    "mean_contents1 = array_annotations_FOLD_3[:len(dic['20120213_seq1_01_01.mat']['SIFT'][1][1])]\n",
    "\n",
    "\n",
    "range_array = np.asarray(list(range(0, len(dic['20120213_seq1_01_01.mat']['SIFT'][1][1]), 1)))\n",
    "\n",
    "fig = plt.figure(figsize=(17, 6))\n",
    "plt.plot(range_array , mean_contents1, 'ro')\n",
    "plt.axis([0,len(dic['20120213_seq1_01_01.mat']['SIFT'][1][1]), 0, 1])\n",
    "fig.suptitle('Ground truth conflict intensity between the 2 participants')\n",
    "plt.xlabel('Number of frames')\n",
    "plt.ylabel('Conflict intensity')\n",
    "plt.show()\n",
    "fig.savefig('meanplot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# whiten the data \n",
    "\n",
    "whitened_data = whiten(Average_Big_list)\n",
    "\n",
    "def svd_whiten(X):\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    X_white = np.dot(U, Vt)\n",
    "\n",
    "    return X_white\n",
    "\n",
    "whiten_Big_list = svd_whiten(Average_Big_list_FOLD_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PCA on the new matrix\n",
    "\n",
    "n_components = 500\n",
    "svd = decomposition.TruncatedSVD(n_components=n_components, algorithm='arpack')\n",
    "svd.fit(Average_Big_list_FOLD_3)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "# 500 components: 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the new data of dimension  (number of frames * 500)\n",
    "\n",
    "svd_data = np.dot(Average_Big_list_FOLD_3,np.transpose(svd.components_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using t-sne on the PCA data to visualize the data (only on 10000 data points for speed purposes)\n",
    "\n",
    "random_indices = np.random.choice(svd_data.shape[0], 10000, replace=False)\n",
    "sampled_rows = svd_data[random_indices, :]\n",
    "sampled_annotations = array_annotations_FOLD_3[random_indices, :]\n",
    "tsne_svd = manifold.TSNE(n_components=2, verbose=0, perplexity=30, n_iter=2500) \n",
    "tsne_results_svd = tsne_svd.fit_transform(sampled_rows) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=3) # k-means\n",
    "kmeans.fit(sampled_rows)\n",
    "\n",
    "c = kmeans.labels_\n",
    "x = tsne_results_svd[:,0]\n",
    "y = tsne_results_svd[:,1]\n",
    "#z = tsne_results_svd[:,2]\n",
    "t = [str(s[0]) for s in sampled_annotations]\n",
    "\n",
    "trace1 = go.Scatter(x=x,y=y,text=t, mode='markers',marker=dict(size=12,color=c, colorscale = 'Viridis', opacity=0.8))\n",
    "data = [trace1]\n",
    "layout = go.Layout(margin=dict(l=0,r=0,b=0,t=0))\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='t-SNE PCA with k-Means')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the data with an RBF Gaussian kernal and perform PCA. Could again use k-means and plot the data in 2 or 3 dimensions\n",
    "# using t-SNE as was done for PCA above.\n",
    "\n",
    "\n",
    "n_components = 500\n",
    "kpca = KernelPCA(kernel=\"rbf\",n_components=n_components, gamma=10)\n",
    "X_kpca = kpca.fit_transform(Average_Big_list_FOLD_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the eigenvalues\n",
    "\n",
    "kpca.lambdas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the name of files of FOLD_4\n",
    "\n",
    "my_data_Fold_4 = genfromtxt('FOLD4.txt', delimiter='\\n', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data from the Google cloud for FOLD_4. \n",
    "# Note that the variable name_of_files is the same one we define in a couple of cells below. (ON THE GOOGLE CLOUD STORAGE)\n",
    "\n",
    "url =  \"https://storage.googleapis.com/bucket-pinouche/ImperialData/FOLD_4\"\n",
    "\n",
    "dic = {}\n",
    "number_of_files = 0\n",
    "\n",
    "for filename in my_data_Fold_4 :\n",
    "    print(filename)\n",
    "    f = urllib.request.urlopen(url+'/'+filename)\n",
    "    with open(os.path.basename(url), \"wb\") as local_file:\n",
    "        local_file.write(f.read())\n",
    "        dic[filename] = sio.loadmat(local_file.name)\n",
    "    \n",
    "    number_of_files = number_of_files + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a similar matrix to Average_big_list but using the data FOLD_4. This is a sueprvised methods (it uses the labels) and\n",
    "# we do not want to use the labels to transform our data which will then be trained using the same labels (introduces bias).\n",
    "\n",
    "# Get all the values from the SIFT values for each of the frame from the dictionnary\n",
    "\n",
    "key=0\n",
    "concat = []\n",
    "\n",
    "for val in my_data_Fold_4:\n",
    "    if(key%2 == 0):\n",
    "        person1 = dic[val]['SIFT']\n",
    "    else:\n",
    "        person2 = dic[val]['SIFT']\n",
    "        concat.append(dataMatrix(person1, person2))\n",
    "    key +=1\n",
    "        \n",
    "Big_list = np.concatenate(concat)\n",
    "print(Big_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take the average for the two people\n",
    "\n",
    "Person1_columns = Big_list[:,:(49*128)]\n",
    "Person2_columns = Big_list[:,(49*128):]\n",
    "print([Person1_columns.shape,Person2_columns.shape])\n",
    "Average_Big_list_FOLD_4 = (Person1_columns + Person2_columns)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The Annotation folder is stored on the virtual machine instance directly (ON THE VIRTUAL MACHINE) for FOLD_4\n",
    "\n",
    "even_names_files = list()\n",
    "index = 0\n",
    "\n",
    "for name in my_data_Fold_4:\n",
    "    if(index%2 == 0):\n",
    "        even_names_files.append(name[:-10])\n",
    "    index += 1\n",
    "\n",
    "dic2 = {}\n",
    "number_of_files = 0\n",
    "path = r'/home/uriot_thomas/two'\n",
    "\n",
    "for filename in even_names_files:\n",
    "    dic2[filename] = sio.loadmat(path+'/'+filename+'/'+'meanAnnotation.mat')\n",
    "    number_of_files = number_of_files + 1\n",
    "    \n",
    "sequences_shape = list()\n",
    "mean_annotations = list()\n",
    "\n",
    "for filename in even_names_files:\n",
    "    mean_annotations.append(dic2[filename]['annotations'])\n",
    "    sequences_shape.append(dic2[filename]['annotations'].shape[0])\n",
    "\n",
    "array_annotations_FOLD_4 = np.concatenate(np.asarray(mean_annotations), axis=0)\n",
    "\n",
    "print([number_of_files, array_annotations_FOLD_4.shape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform CCA\n",
    "\n",
    "cca = CCA(n_components=500)\n",
    "cca.fit(Average_Big_list_FOLD_4, array_annotations_FOLD_4)  # THIS IS THE TRAINING PART WHICH NEEDS TO BE DONE ON A DIFFERENT FOLD\n",
    "print(cca.coef_.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "\n",
    "cca_data = cca.transform(Average_Big_list) # HERE THIS IS THE USUAL DATA ON FOLD_3\n",
    "print(cca_data) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
